<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>A Beginner&#39;s Guide to Gradient Descent - Understanding the Core of Machine Learning Optimization | shreyy.inc</title>
<meta name="keywords" content="">
<meta name="description" content="In this blog, I will try to explain what exactly is gradient descent and it&rsquo;s importance in optimizing machine learning models. Gradient descent is an algorithm (just like million other algorithms that exists in computer science) that is designed to minimize a cost function.
What is a cost function?

Well, it is essentially the error between predicted and actual outputs. Which means if we want to increase our model&rsquo;s accuracy, we need to somehow reduce this cost function and for that we&rsquo;ve got gradient descent.

What is a Gradient?

A gradient is essentially the derivative of a function, which tells us how the output is affected with little variations in input. This gradient, helps us in adjusting model parameters (like weights and biases) to reduce the cost function.

Why Gradient Descent?

It helps us in minimizing the error in predictions, bringing the model closer to the actual data. It iteratively keep adjusting the model&rsquo;s parameters until minimum cost function state is achieved.
This iterative process ensures the model learns and improves its performance.

What are Weights and Biases?
Weights: Weights (W) are parameters that define influence of an input on the model&rsquo;s output.
Biases: Biases (b) is an additional parameter that shifts the model&rsquo;s prediction.">
<meta name="author" content="by Shreyy">
<link rel="canonical" href="/blogs/gradientdescent/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.f49d66caae9ea0fd43f21f29e71a8d3e284517ed770f2aa86fa012953ad3c9ef.css" integrity="sha256-9J1myq6eoP1D8h8p5xqNPihFF&#43;13Dyqob6ASlTrTye8=" rel="preload stylesheet" as="style">
<link rel="icon" href="/favicon.ico" sizes="any">
<link rel="icon" href="/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
<link rel="apple-touch-icon" href="/apple-touch-icon.png">
<link rel="mask-icon" href="/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="/blogs/gradientdescent/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:url" content="/blogs/gradientdescent/">
  <meta property="og:site_name" content="shreyy.inc">
  <meta property="og:title" content="A Beginner&#39;s Guide to Gradient Descent - Understanding the Core of Machine Learning Optimization">
  <meta property="og:description" content="In this blog, I will try to explain what exactly is gradient descent and it’s importance in optimizing machine learning models. Gradient descent is an algorithm (just like million other algorithms that exists in computer science) that is designed to minimize a cost function.
What is a cost function? Well, it is essentially the error between predicted and actual outputs. Which means if we want to increase our model’s accuracy, we need to somehow reduce this cost function and for that we’ve got gradient descent. What is a Gradient? A gradient is essentially the derivative of a function, which tells us how the output is affected with little variations in input. This gradient, helps us in adjusting model parameters (like weights and biases) to reduce the cost function. Why Gradient Descent? It helps us in minimizing the error in predictions, bringing the model closer to the actual data. It iteratively keep adjusting the model’s parameters until minimum cost function state is achieved. This iterative process ensures the model learns and improves its performance. What are Weights and Biases? Weights: Weights (W) are parameters that define influence of an input on the model’s output. Biases: Biases (b) is an additional parameter that shifts the model’s prediction.">
  <meta property="og:locale" content="en-us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="blogs">
    <meta property="article:published_time" content="2024-12-22T19:16:40+05:30">
    <meta property="article:modified_time" content="2024-12-22T19:16:40+05:30">
    <meta property="og:image" content="/images/gradient.webp">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="/images/gradient.webp">
<meta name="twitter:title" content="A Beginner&#39;s Guide to Gradient Descent - Understanding the Core of Machine Learning Optimization">
<meta name="twitter:description" content="In this blog, I will try to explain what exactly is gradient descent and it&rsquo;s importance in optimizing machine learning models. Gradient descent is an algorithm (just like million other algorithms that exists in computer science) that is designed to minimize a cost function.
What is a cost function?

Well, it is essentially the error between predicted and actual outputs. Which means if we want to increase our model&rsquo;s accuracy, we need to somehow reduce this cost function and for that we&rsquo;ve got gradient descent.

What is a Gradient?

A gradient is essentially the derivative of a function, which tells us how the output is affected with little variations in input. This gradient, helps us in adjusting model parameters (like weights and biases) to reduce the cost function.

Why Gradient Descent?

It helps us in minimizing the error in predictions, bringing the model closer to the actual data. It iteratively keep adjusting the model&rsquo;s parameters until minimum cost function state is achieved.
This iterative process ensures the model learns and improves its performance.

What are Weights and Biases?
Weights: Weights (W) are parameters that define influence of an input on the model&rsquo;s output.
Biases: Biases (b) is an additional parameter that shifts the model&rsquo;s prediction.">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Blogs",
      "item": "/blogs/"
    }
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "A Beginner's Guide to Gradient Descent - Understanding the Core of Machine Learning Optimization",
      "item": "/blogs/gradientdescent/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "A Beginner's Guide to Gradient Descent - Understanding the Core of Machine Learning Optimization",
  "name": "A Beginner\u0027s Guide to Gradient Descent - Understanding the Core of Machine Learning Optimization",
  "description": "In this blog, I will try to explain what exactly is gradient descent and it\u0026rsquo;s importance in optimizing machine learning models. Gradient descent is an algorithm (just like million other algorithms that exists in computer science) that is designed to minimize a cost function.\nWhat is a cost function? Well, it is essentially the error between predicted and actual outputs. Which means if we want to increase our model\u0026rsquo;s accuracy, we need to somehow reduce this cost function and for that we\u0026rsquo;ve got gradient descent. What is a Gradient? A gradient is essentially the derivative of a function, which tells us how the output is affected with little variations in input. This gradient, helps us in adjusting model parameters (like weights and biases) to reduce the cost function. Why Gradient Descent? It helps us in minimizing the error in predictions, bringing the model closer to the actual data. It iteratively keep adjusting the model\u0026rsquo;s parameters until minimum cost function state is achieved. This iterative process ensures the model learns and improves its performance. What are Weights and Biases? Weights: Weights (W) are parameters that define influence of an input on the model\u0026rsquo;s output. Biases: Biases (b) is an additional parameter that shifts the model\u0026rsquo;s prediction.\n",
  "keywords": [
    
  ],
  "articleBody": "In this blog, I will try to explain what exactly is gradient descent and it’s importance in optimizing machine learning models. Gradient descent is an algorithm (just like million other algorithms that exists in computer science) that is designed to minimize a cost function.\nWhat is a cost function? Well, it is essentially the error between predicted and actual outputs. Which means if we want to increase our model’s accuracy, we need to somehow reduce this cost function and for that we’ve got gradient descent. What is a Gradient? A gradient is essentially the derivative of a function, which tells us how the output is affected with little variations in input. This gradient, helps us in adjusting model parameters (like weights and biases) to reduce the cost function. Why Gradient Descent? It helps us in minimizing the error in predictions, bringing the model closer to the actual data. It iteratively keep adjusting the model’s parameters until minimum cost function state is achieved. This iterative process ensures the model learns and improves its performance. What are Weights and Biases? Weights: Weights (W) are parameters that define influence of an input on the model’s output. Biases: Biases (b) is an additional parameter that shifts the model’s prediction.\nFor Example, If we consider a model that is trained to determine house prices based on the area (in Sq. m), then in this case area’s impact on the price of the house is weight and other factors such as location, or the number of bedrooms are biases that can shift the prediction.\nHow does Gradient Descent Work? Firstly, we take a starting point (it can be any point as it’s just an arbitary point for us to evaluate the performance). Then the derivative (or slope) is calculated at this point, after which we can use a tangent line to observe the steepness of the slope. Finding out the slope is an important step as it will inform what updates need to be made to the parameters- i.e. the weights and bias. The starting point of the slope will be steeper, but as new parameters are generated, the steepness will gradually reduce and will slowly near zero as we reach the lowest point on the curve. This lowest point on the curve is known as the point of convergence.\nLike in linear regression, we try to find the bet fit line, the goal of gradient is to minimize the error between the predicted y and the actual y. In order to achieve this goal, it requires two data points- a direction and a learning rate. These factors determine the partial derivative calculations of future iterations, allowing it to gradually arrive at the local or global minimum (i.e. point of convergence).\nSteps: 1. Starting Point: Begin with initial parameter values, often set arbitrarily. 2. Calculate the Slope: Determine the gradient at this point to assess the steepness and direction of the slope. 3. Update Parameters: Use the slope to adjust the parameters, iteratively reducing the steepness until the curve flattens at the minimum. 4. Convergence: Continue until the gradient approaches zero, signifying that the minimum has been reached.\nKey Components Learning Rate (α) Determines the size of step we take after each calculation or the variation in input.\nHigh learning rate takes larger steps which speeds up the process but also increases the risk of overshooting the minimum. Low learning rate ensures precise steps but increases computation time as the number of iterations increases. Cost Function The cost function quantifies the error between the predicted output and the actual output.\nIt guides the model by providing feedback, enabling parameter updates to minimize the error. A loss function refers to the error for a single training example, while the cost function averages this error across the entire dataset. ",
  "wordCount" : "631",
  "inLanguage": "en",
  "image":"/images/gradient.webp","datePublished": "2024-12-22T19:16:40+05:30",
  "dateModified": "2024-12-22T19:16:40+05:30",
  "author":{
    "@type": "Person",
    "name": "by Shreyy"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "/blogs/gradientdescent/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "shreyy.inc",
    "logo": {
      "@type": "ImageObject",
      "url": "/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="/" accesskey="h" title="shreyy.inc (Alt + H)">shreyy.inc</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="/">Home</a>&nbsp;»&nbsp;<a href="/blogs/">Blogs</a></div>
    <h1 class="post-title entry-hint-parent">
      A Beginner&#39;s Guide to Gradient Descent - Understanding the Core of Machine Learning Optimization
    </h1>
    <div class="post-meta"><span title='2024-12-22 19:16:40 +0530 IST'>December 22, 2024</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;by Shreyy

</div>
  </header> 
<figure class="entry-cover">
        <img loading="eager" src="/images/gradient.webp" alt="Cover Photo">
        
</figure>

  
    
  
  <div class="post-content"><p>In this blog, I will try to explain what exactly is <strong>gradient descent</strong> and it&rsquo;s importance in optimizing machine learning models. Gradient descent is an algorithm (just like million other algorithms that exists in computer science) that is designed to minimize a <strong>cost function</strong>.</p>
<h3 id="what-is-a-cost-function">What is a cost function?<a hidden class="anchor" aria-hidden="true" href="#what-is-a-cost-function">#</a></h3>
<ul>
<li>Well, it is essentially the error between predicted and actual outputs. Which means if we want to increase our model&rsquo;s accuracy, we need to somehow reduce this cost function and for that we&rsquo;ve got gradient descent.</li>
</ul>
<h3 id="what-is-a-gradient">What is a Gradient?<a hidden class="anchor" aria-hidden="true" href="#what-is-a-gradient">#</a></h3>
<ul>
<li>A gradient is essentially the derivative of a function, which tells us how the output is affected with little variations in input. This gradient, helps us in adjusting model parameters <em>(like weights and biases)</em> to reduce the cost function.</li>
</ul>
<h3 id="why-gradient-descent">Why Gradient Descent?<a hidden class="anchor" aria-hidden="true" href="#why-gradient-descent">#</a></h3>
<ul>
<li>It helps us in minimizing the error in predictions, bringing the model closer to the actual data. It iteratively keep adjusting the model&rsquo;s parameters until minimum cost function state is achieved.</li>
<li>This iterative process ensures the model learns and improves its performance.</li>
</ul>
<h3 id="what-are-weights-and-biases">What are Weights and Biases?<a hidden class="anchor" aria-hidden="true" href="#what-are-weights-and-biases">#</a></h3>
<p><strong>Weights:</strong> Weights (W) are parameters that define influence of an input on the model&rsquo;s output.
<strong>Biases:</strong> Biases (b) is an additional parameter that shifts the model&rsquo;s prediction.</p>
<p>For Example, If we consider a model that is trained to determine house prices based on the area (in Sq. m), then in this case area&rsquo;s impact on the price of the house is weight and other factors such as location, or the number of bedrooms are biases that can shift the prediction.</p>
<h3 id="how-does-gradient-descent-work">How does Gradient Descent Work?<a hidden class="anchor" aria-hidden="true" href="#how-does-gradient-descent-work">#</a></h3>
<p>Firstly, we take a starting point (it can be any point as it&rsquo;s just an arbitary point for us to evaluate the performance). Then the derivative (or slope) is calculated at this point, after which we can use a tangent line to observe the steepness of the slope. Finding out the slope is an important step as it will inform what updates need to be made to the parameters- i.e. the weights and bias. The starting point of the slope will be steeper, but as new parameters are generated, the steepness will gradually reduce and will slowly near zero as we reach the lowest point on the curve. This lowest point on the curve is known as the point of convergence.</p>
<p>Like in linear regression, we try to find the bet fit line, the goal of gradient is to minimize the error between the predicted y and the actual y. In order to achieve this goal, it requires two data points- a direction and a learning rate. These factors determine the partial derivative calculations of future iterations, allowing it to gradually arrive at the local or global minimum (i.e. point of convergence).</p>
<h3 id="steps">Steps:<a hidden class="anchor" aria-hidden="true" href="#steps">#</a></h3>
<p><strong>1. Starting Point:</strong> Begin with initial parameter values, often set arbitrarily.
<strong>2. Calculate the Slope:</strong> Determine the gradient at this point to assess the steepness and direction of the slope.
<strong>3. Update Parameters:</strong> Use the slope to adjust the parameters, iteratively reducing the steepness until the curve flattens at the minimum.
<strong>4. Convergence:</strong> Continue until the gradient approaches zero, signifying that the minimum has been reached.</p>
<h3 id="key-components">Key Components<a hidden class="anchor" aria-hidden="true" href="#key-components">#</a></h3>
<ol>
<li>
<p><strong>Learning Rate (α)</strong>
Determines the size of step we take after each calculation or the variation in input.</p>
<ul>
<li><em>High learning rate</em> takes larger steps which speeds up the process but also increases the risk of overshooting the minimum.</li>
<li><em>Low learning rate</em> ensures precise steps but increases computation time as the number of iterations increases.</li>
</ul>
</li>
<li>
<p><strong>Cost Function</strong>
The cost function quantifies the error between the predicted output and the actual output.</p>
<ul>
<li>It guides the model by providing feedback, enabling parameter updates to minimize the error.</li>
<li>A <em>loss function</em> refers to the error for a single training example, while the <em>cost function</em> averages this error across the entire dataset.</li>
</ul>
</li>
</ol>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>

  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="/">shreyy.inc</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
