<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Blogs on eschaos</title>
    <link>/blogs/</link>
    <description>Recent content in Blogs on eschaos</description>
    <generator>Hugo -- 0.147.0</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 22 Dec 2024 19:16:40 +0530</lastBuildDate>
    <atom:link href="/blogs/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>A Beginner&#39;s Guide to Gradient Descent - Understanding the Core of Machine Learning Optimization</title>
      <link>/blogs/gradientdescent/</link>
      <pubDate>Sun, 22 Dec 2024 19:16:40 +0530</pubDate>
      <guid>/blogs/gradientdescent/</guid>
      <description>&lt;p&gt;In this blog, I will try to explain what exactly is &lt;strong&gt;gradient descent&lt;/strong&gt; and it&amp;rsquo;s importance in optimizing machine learning models. Gradient descent is an algorithm (just like million other algorithms that exists in computer science) that is designed to minimize a &lt;strong&gt;cost function&lt;/strong&gt;.&lt;/p&gt;
&lt;h3 id=&#34;what-is-a-cost-function&#34;&gt;What is a cost function?&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Well, it is essentially the error between predicted and actual outputs. Which means if we want to increase our model&amp;rsquo;s accuracy, we need to somehow reduce this cost function and for that we&amp;rsquo;ve got gradient descent.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;what-is-a-gradient&#34;&gt;What is a Gradient?&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;A gradient is essentially the derivative of a function, which tells us how the output is affected with little variations in input. This gradient, helps us in adjusting model parameters &lt;em&gt;(like weights and biases)&lt;/em&gt; to reduce the cost function.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;why-gradient-descent&#34;&gt;Why Gradient Descent?&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;It helps us in minimizing the error in predictions, bringing the model closer to the actual data. It iteratively keep adjusting the model&amp;rsquo;s parameters until minimum cost function state is achieved.&lt;/li&gt;
&lt;li&gt;This iterative process ensures the model learns and improves its performance.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;what-are-weights-and-biases&#34;&gt;What are Weights and Biases?&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Weights:&lt;/strong&gt; Weights (W) are parameters that define influence of an input on the model&amp;rsquo;s output.
&lt;strong&gt;Biases:&lt;/strong&gt; Biases (b) is an additional parameter that shifts the model&amp;rsquo;s prediction.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
